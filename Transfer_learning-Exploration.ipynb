{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca221599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "from torchvision import models,datasets,transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d003bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Data/train'\n",
    "test_path = 'Data/validation'\n",
    "\n",
    "# Transformations \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.tensor([0.5,0.5,0.5]),torch.tensor([0.5,0.5,0.5]))\n",
    "  ])\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.tensor([0.5,0.5,0.5]),torch.tensor([0.5,0.5,0.5]))\n",
    "  ])\n",
    "\n",
    "# Dataset \n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_path,transform = train_transform)\n",
    "test_data = datasets.ImageFolder(root=test_path,transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76c4119a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 44\n",
       "    Root location: Data/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
       "               RandomRotation(degrees=[-20.0, 20.0], interpolation=nearest, expand=False, fill=0)\n",
       "               ToTensor()\n",
       "               Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=tensor([0.5000, 0.5000, 0.5000]))\n",
       "           )"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3501321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 44\n",
       "    Root location: Data/validation\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
       "               ToTensor()\n",
       "               Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=tensor([0.5000, 0.5000, 0.5000]))\n",
       "           )"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7edeb3e",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b6711f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg11_bn(num_classes=2,pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b35db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10  loss : 1.120194911956787\n",
      "Epoch 0/10  loss : 1.8671547174453735\n",
      "Epoch 1/10  loss : 3.2493181228637695\n",
      "Epoch 1/10  loss : 0.9218428134918213\n",
      "Epoch 2/10  loss : 1.3246116638183594\n",
      "Epoch 2/10  loss : 0.693638265132904\n",
      "Epoch 3/10  loss : 1.1003941297531128\n",
      "Epoch 3/10  loss : 1.2613991498947144\n",
      "Epoch 4/10  loss : 1.088152527809143\n",
      "Epoch 4/10  loss : 1.885624885559082\n",
      "Epoch 5/10  loss : 0.6935417652130127\n",
      "Epoch 5/10  loss : 0.704929530620575\n",
      "Epoch 6/10  loss : 2.114464044570923\n",
      "Epoch 6/10  loss : 0.7788889408111572\n",
      "Epoch 7/10  loss : 2.1979308128356934\n",
      "Epoch 7/10  loss : 1.2055258750915527\n",
      "Epoch 8/10  loss : 1.739746332168579\n",
      "Epoch 8/10  loss : 1.5544229745864868\n",
      "Epoch 9/10  loss : 1.0130209922790527\n",
      "Epoch 9/10  loss : 0.8602206707000732\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data,shuffle=True,batch_size=32)\n",
    "test_loader = DataLoader(test_data,shuffle=False,batch_size=32)\n",
    "\n",
    "vgg.train()\n",
    "n_epochs = 10\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vgg.parameters())\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch ,data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = vgg(data[0])\n",
    "        loss = loss_func(pred,data[1])\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch}/{n_epochs}  loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c3cfe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.eval()\n",
    "n_sample = 0\n",
    "n_correct = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, data in enumerate(test_loader):\n",
    "        x = data[0]\n",
    "        y = data[1]\n",
    "        y_pred = vgg(x)\n",
    "        n_correct += (torch.argmax(y_pred,axis=1) == y).sum()\n",
    "        n_sample +=y.shape[0]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "def40e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5369ae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy = (n_correct/n_sample)*100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81edf44e",
   "metadata": {},
   "source": [
    "# Check Whether Layers are frozen or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ac01762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un frezze all layers\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e511f16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight 1728\n"
     ]
    }
   ],
   "source": [
    "for name,param in vgg.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param.numel())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6dc77f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frezze all layers \n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c82c083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "for name,param in vgg.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name,param.numel()) \n",
    "else:\n",
    "    print('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e3a524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG Pretrained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "70407284",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VGG:\n\tsize mismatch for classifier.6.weight: copying a param with shape torch.Size([1000, 4096]) from checkpoint, the shape in current model is torch.Size([2, 4096]).\n\tsize mismatch for classifier.6.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-545cbdf44027>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg11_bn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mvgg11_bn\u001b[1;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplays\u001b[0m \u001b[0ma\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0mbar\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \"\"\"\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_vgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vgg11_bn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'A'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36m_vgg\u001b[1;34m(arch, cfg, batch_norm, pretrained, progress, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m         state_dict = load_state_dict_from_url(model_urls[arch],\n\u001b[0;32m    100\u001b[0m                                               progress=progress)\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1482\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1484\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VGG:\n\tsize mismatch for classifier.6.weight: copying a param with shape torch.Size([1000, 4096]) from checkpoint, the shape in current model is torch.Size([2, 4096]).\n\tsize mismatch for classifier.6.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "vgg = models.vgg11_bn(num_classes=2,pretrained=True)\n",
    "\n",
    "vgg.eval()\n",
    "n_sample = 0\n",
    "n_correct = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, data in enumerate(test_loader):\n",
    "        x = data[0]\n",
    "        y = data[1]\n",
    "        y_pred = vgg(x)\n",
    "        n_correct += (torch.argmax(y_pred,axis=1) == y).sum()\n",
    "        n_sample +=y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2deea63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (n_correct/n_sample)*100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2370d6",
   "metadata": {},
   "source": [
    "# Conclusion: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80942a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Any , Model we are using is attached to its main class \n",
    "   # Example if VGG main class\n",
    "   # vgg11 -- > base class \n",
    "   # -- vgg11 -- pretrained = False\n",
    "   # --- vgg11 -- pretrained = True \n",
    "\n",
    "# If pretrained = False: \n",
    "   #  you can use it train it , change number of classes \n",
    "\n",
    "# If Pretrained = True\n",
    "   # Then first model will be downloaded \n",
    "   # In transfer change the number of class and then retrain it \n",
    "   # then eval \n",
    "# else: \n",
    "  # error "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_LinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPREOKB9iNbh"
      },
      "source": [
        "# Pytorch - Linear Regression \n",
        "I have coverd all the approches to train a linear model which includes \n",
        "1. Simple linear model \n",
        "2. Sequential Implementation (Added Non linearity )\n",
        "   (Wanted you to see effect of NL:)\n",
        "3. Functional Implementation (Added Non linearity )\n",
        "\n",
        "Hope You will find it interesting and point to point.!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftnJHnmrgxaI"
      },
      "source": [
        "# Basic Imports  \n",
        "import torch           # Main torch lib \n",
        "import torch.nn as nn  # nn module contains all usefull functions \n",
        "import numpy as np     \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "from torch.utils.data import TensorDataset , DataLoader \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "z6z77vhLhM1H",
        "outputId": "63283095-fddc-4f7e-a5a2-71f57adbb3cc"
      },
      "source": [
        "# Uploading csv file on colab for Linear Regression \n",
        "# cement Slump Data \n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3f8d27db-82ef-431e-a9ce-82b43e588a92\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3f8d27db-82ef-431e-a9ce-82b43e588a92\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cement_slump.csv to cement_slump.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cement_slump.csv': b'Cement,Slag,Fly ash,Water,SP,Coarse Aggr.,Fine Aggr.,SLUMP(cm),FLOW(cm),Compressive Strength (28-day)(Mpa)\\r\\n273,82,105,210,9,904,680,23,62,34.99\\r\\n163,149,191,180,12,843,746,0,20,41.14\\r\\n162,148,191,179,16,840,743,1,20,41.81\\r\\n162,148,190,179,19,838,741,3,21.5,42.08\\r\\n154,112,144,220,10,923,658,20,64,26.82\\r\\n147,89,115,202,9,860,829,23,55,25.21\\r\\n152,139,178,168,18,944,695,0,20,38.86\\r\\n145,0,227,240,6,750,853,14.5,58.5,36.59\\r\\n152,0,237,204,6,785,892,15.5,51,32.71\\r\\n304,0,140,214,6,895,722,19,51,38.46\\r\\n145,106,136,208,10,751,883,24.5,61,26.02\\r\\n148,109,139,193,7,768,902,23.75,58,28.03\\r\\n142,130,167,215,6,735,836,25.5,67,31.37\\r\\n354,0,0,234,6,959,691,17,54,33.91\\r\\n374,0,0,190,7,1013,730,14.5,42.5,32.44\\r\\n159,116,149,175,15,953,720,23.5,54.5,34.05\\r\\n153,0,239,200,6,1002,684,12,35,28.29\\r\\n295,106,136,206,11,750,766,25,68.5,41.01\\r\\n310,0,143,168,10,914,804,20.5,48.2,49.3\\r\\n296,97,0,219,9,932,685,15,48.5,29.23\\r\\n305,100,0,196,10,959,705,20,49,29.77\\r\\n310,0,143,218,10,787,804,13,46,36.19\\r\\n148,180,0,183,11,972,757,0,20,18.52\\r\\n146,178,0,192,11,961,749,18,46,17.19\\r\\n142,130,167,174,11,883,785,0,20,36.72\\r\\n140,128,164,183,12,871,775,23.75,53,33.38\\r\\n308,111,142,217,10,783,686,25,70,42.08\\r\\n295,106,136,208,6,871,650,26.5,70,39.4\\r\\n298,107,137,201,6,878,655,16,26,41.27\\r\\n314,0,161,207,6,851,757,21.5,64,41.14\\r\\n321,0,164,190,5,870,774,24,60,45.82\\r\\n349,0,178,230,6,785,721,20,68.5,43.95\\r\\n366,0,187,191,7,824,757,24.75,62.7,52.65\\r\\n274,89,115,202,9,759,827,26.5,68,35.52\\r\\n137,167,214,226,6,708,757,27.5,70,34.45\\r\\n275,99,127,184,13,810,790,25.75,64.5,43.54\\r\\n252,76,97,194,8,835,821,23,54,33.11\\r\\n165,150,0,182,12,1023,729,14.5,20,18.26\\r\\n158,0,246,174,7,1035,706,19,43,34.99\\r\\n156,0,243,180,11,1022,698,21,57,33.78\\r\\n145,177,227,209,11,752,715,2.5,20,35.66\\r\\n154,141,181,234,11,797,683,23,65,33.51\\r\\n160,146,188,203,11,829,710,13,38,33.51\\r\\n291,105,0,205,6,859,797,24,59,27.62\\r\\n298,107,0,186,6,879,815,3,20,30.97\\r\\n318,126,0,210,6,861,737,17.5,48,31.77\\r\\n280,92,118,207,9,883,679,25.5,64,37.39\\r\\n287,94,121,188,9,904,696,25,61,43.01\\r\\n332,0,170,160,6,900,806,0,20,58.53\\r\\n326,0,167,174,6,884,792,21.5,42,52.65\\r\\n320,0,163,188,9,866,776,23.5,60,45.69\\r\\n342,136,0,225,11,770,747,21,61,32.04\\r\\n356,142,0,193,11,801,778,8,30,36.46\\r\\n309,0,142,218,10,912,680,24,62,38.59\\r\\n322,0,149,186,8,951,709,20.5,61.5,45.42\\r\\n159,193,0,208,12,821,818,23,50,19.19\\r\\n307,110,0,189,10,904,765,22,40,31.5\\r\\n313,124,0,205,11,846,758,22,49,29.63\\r\\n143,131,168,217,6,891,672,25,69,26.42\\r\\n140,128,164,237,6,869,656,24,65,29.5\\r\\n278,0,117,205,9,875,799,19,48,32.71\\r\\n288,0,121,177,7,908,829,22.5,48.5,39.93\\r\\n299,107,0,210,10,881,745,25,63,28.29\\r\\n291,104,0,231,9,857,725,23,69,30.43\\r\\n265,86,111,195,6,833,790,27,60,37.39\\r\\n159,0,248,175,12,1041,683,21,51,35.39\\r\\n160,0,250,168,12,1049,688,18,48,37.66\\r\\n166,0,260,183,13,859,827,21,54,40.34\\r\\n320,127,164,211,6,721,723,2,20,46.36\\r\\n336,134,0,222,6,756,787,26,64,31.9\\r\\n276,90,116,180,9,870,768,0,20,44.08\\r\\n313,112,0,220,10,794,789,23,58,28.16\\r\\n322,116,0,196,10,818,813,25.5,67,29.77\\r\\n294,106,136,207,6,747,778,24,47,41.27\\r\\n146,106,137,209,6,875,765,24,67,27.89\\r\\n149,109,139,193,6,892,780,23.5,58.5,28.7\\r\\n159,0,187,176,11,990,789,12,39,32.57\\r\\n261,78,100,201,9,864,761,23,63.5,34.18\\r\\n140,1.4,198.1,174.9,4.4,1049.9,780.5,16.25,31,30.83\\r\\n141.1,0.6,209.5,188.8,4.6,996.1,789.2,23.5,53,30.43\\r\\n140.1,4.2,215.9,193.9,4.7,1049.5,710.1,24.5,57,26.42\\r\\n140.1,11.8,226.1,207.8,4.9,1020.9,683.8,21,64,26.28\\r\\n160.2,0.3,240,233.5,9.2,781,841.1,24,75,36.19\\r\\n140.2,30.5,239,169.4,5.3,1028.4,742.7,21.25,46,36.32\\r\\n140.2,44.8,234.9,171.3,5.5,1047.6,704,23.5,52.5,33.78\\r\\n140.5,61.1,238.9,182.5,5.7,1017.7,681.4,24.5,60,30.97\\r\\n143.3,91.8,239.8,200.8,6.2,964.8,647.1,25,55,27.09\\r\\n194.3,0.3,240,234.2,8.9,780.6,811.3,26.5,78,38.46\\r\\n150.4,110.9,239.7,168.1,6.5,1000.2,667.2,9.5,27.5,37.92\\r\\n150.3,111.4,238.8,167.3,6.5,999.5,670.5,14.5,36.5,38.19\\r\\n155.4,122.1,240,179.9,6.7,966.8,652.5,14.5,41.5,35.52\\r\\n165.3,143.2,238.3,200.4,7.1,883.2,652.6,17,27,32.84\\r\\n303.8,0.2,239.8,236.4,8.3,780.1,715.3,25,78,44.48\\r\\n172,162.1,238.5,166,7.4,953.3,641.4,0,20,41.54\\r\\n172.8,158.3,239.5,166.4,7.4,952.6,644.1,0,20,41.81\\r\\n184.3,153.4,239.2,179,7.5,920.2,640.9,0,20,41.01\\r\\n215.6,112.9,239,198.7,7.4,884,649.1,27.5,64,39.13\\r\\n295.3,0,239.9,236.2,8.3,780.3,722.9,25,77,44.08\\r\\n248.3,101,239.1,168.9,7.7,954.2,640.6,0,20,49.97\\r\\n248,101,239.9,169.1,7.7,949.9,644.1,2,20,50.23\\r\\n258.8,88,239.6,175.3,7.6,938.9,646,0,20,50.5\\r\\n297.1,40.9,239.9,194,7.5,908.9,651.8,27.5,67,49.17\\r\\n348.7,0.1,223.1,208.5,9.6,786.2,758.1,29,78,48.7\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lktto6eqkheh"
      },
      "source": [
        "# UCI REPOSITORY \n",
        "# To show Linear regression I am using cement slump dataset \n",
        "## Official link : https://archive.ics.uci.edu/ml/datasets/concrete+slump+test\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruixl9fLJGie"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4L2zrX1iNLa",
        "outputId": "2623712e-662b-41ae-efa5-95f7c5014eae"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cement_slump.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKz_9Zcch0GP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "89cf017b-39b9-43ba-99cf-506ab237fa63"
      },
      "source": [
        "df = pd.read_csv('cement_slump.csv')\n",
        "df.head()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Slag</th>\n",
              "      <th>Fly ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>SP</th>\n",
              "      <th>Coarse Aggr.</th>\n",
              "      <th>Fine Aggr.</th>\n",
              "      <th>SLUMP(cm)</th>\n",
              "      <th>FLOW(cm)</th>\n",
              "      <th>Compressive Strength (28-day)(Mpa)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>273.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>904.0</td>\n",
              "      <td>680.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>34.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>843.0</td>\n",
              "      <td>746.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>41.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>162.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>840.0</td>\n",
              "      <td>743.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>41.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>162.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>838.0</td>\n",
              "      <td>741.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>21.5</td>\n",
              "      <td>42.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>154.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>923.0</td>\n",
              "      <td>658.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>26.82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement   Slag  ...  FLOW(cm)  Compressive Strength (28-day)(Mpa)\n",
              "0   273.0   82.0  ...      62.0                               34.99\n",
              "1   163.0  149.0  ...      20.0                               41.14\n",
              "2   162.0  148.0  ...      20.0                               41.81\n",
              "3   162.0  148.0  ...      21.5                               42.08\n",
              "4   154.0  112.0  ...      64.0                               26.82\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sl3Y-4ViB0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc3dbb4-1577-4595-81d8-661fabcb4946"
      },
      "source": [
        "# No missing Values -- so we can directly start working on model building and training \n",
        "df.isnull().sum()"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cement                                0\n",
              "Slag                                  0\n",
              "Fly ash                               0\n",
              "Water                                 0\n",
              "SP                                    0\n",
              "Coarse Aggr.                          0\n",
              "Fine Aggr.                            0\n",
              "SLUMP(cm)                             0\n",
              "FLOW(cm)                              0\n",
              "Compressive Strength (28-day)(Mpa)    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uk1VpJOi1HA"
      },
      "source": [
        "# Data - Target Split \n",
        "# Here we have 3 Target Variables \n",
        "X = df.drop(['SLUMP(cm)','FLOW(cm)','Compressive Strength (28-day)(Mpa)'],axis=1)\n",
        "y = df[['SLUMP(cm)','FLOW(cm)','Compressive Strength (28-day)(Mpa)']]"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "r75JNaFloI4K",
        "outputId": "132b63c1-754f-4756-f1a4-92642bd31f60"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Slag</th>\n",
              "      <th>Fly ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>SP</th>\n",
              "      <th>Coarse Aggr.</th>\n",
              "      <th>Fine Aggr.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>273.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>904.0</td>\n",
              "      <td>680.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>843.0</td>\n",
              "      <td>746.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>162.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>840.0</td>\n",
              "      <td>743.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>162.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>838.0</td>\n",
              "      <td>741.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>154.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>923.0</td>\n",
              "      <td>658.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement   Slag  Fly ash  Water    SP  Coarse Aggr.  Fine Aggr.\n",
              "0   273.0   82.0    105.0  210.0   9.0         904.0       680.0\n",
              "1   163.0  149.0    191.0  180.0  12.0         843.0       746.0\n",
              "2   162.0  148.0    191.0  179.0  16.0         840.0       743.0\n",
              "3   162.0  148.0    190.0  179.0  19.0         838.0       741.0\n",
              "4   154.0  112.0    144.0  220.0  10.0         923.0       658.0"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pBTm9amSoLjR",
        "outputId": "e2361f71-4c9a-4be0-be91-41ab58689603"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SLUMP(cm)</th>\n",
              "      <th>FLOW(cm)</th>\n",
              "      <th>Compressive Strength (28-day)(Mpa)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>34.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>41.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>41.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>21.5</td>\n",
              "      <td>42.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>26.82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SLUMP(cm)  FLOW(cm)  Compressive Strength (28-day)(Mpa)\n",
              "0       23.0      62.0                               34.99\n",
              "1        0.0      20.0                               41.14\n",
              "2        1.0      20.0                               41.81\n",
              "3        3.0      21.5                               42.08\n",
              "4       20.0      64.0                               26.82"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpXrkzG8pf0C",
        "outputId": "1fda191a-30f5-4db7-983e-e6ac159c00c6"
      },
      "source": [
        "# By default pytorch uses float32 Tensor and numpy uses float64 \n",
        "# Float 32 is much faster in operations than float64 \n",
        "# So we will convert ndarry to pytorch tensor \n",
        "\n",
        "# Current dtype\n",
        "print(X.values.dtype)\n",
        "print(y.values.dtype)\n",
        "\n",
        "# Pytorch uses shape(rows,cols) so reshaped X and y \n",
        "X = X.values.astype(np.float32).reshape(X.shape[0],-1)\n",
        "y = y.values.astype(np.float32).reshape(y.shape[0],3)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIcfxA_hE9G-"
      },
      "source": [
        "# Converted nd.array into torch tensor \n",
        "X = torch.from_numpy(X)\n",
        "y = torch.from_numpy(y)"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyoC4RNcFny5",
        "outputId": "9acbc067-a72f-4a41-b283-52d34e10ec74"
      },
      "source": [
        "print(X.dtype)\n",
        "print(type(X))"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60C8gfzEhXWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f92731-96c3-4c1f-c6f9-fca040a7c1c3"
      },
      "source": [
        "# Lets do the Train - Test split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=101)\n",
        "len(X_train) , len(y_train) , len(X_test) , len(y_test) "
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77, 77, 26, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xFielWSj7Xp"
      },
      "source": [
        "# Lets Create Dataloader so we can get a batch of 32 \n",
        "# To do this first we need to create a iterable of x and y \n",
        "# Which we can do with TensorDataset \n",
        "\n",
        "train_data = TensorDataset(X_train,y_train)\n",
        "test_data = TensorDataset(X_test,y_test)"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUu2IlmqG6wt",
        "outputId": "9b7e6800-c93a-47fc-df1a-818852c36dd5"
      },
      "source": [
        "train_data[0:1]"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.4110e+02, 6.0000e-01, 2.0950e+02, 1.8880e+02, 4.6000e+00, 9.9610e+02,\n",
              "          7.8920e+02]]), tensor([[23.5000, 53.0000, 30.4300]]))"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MST03QJAG-28"
      },
      "source": [
        "# Since it is now tuple of tensor we can load it in dataloader to get batches\n",
        "train_data_loader = DataLoader(train_data,batch_size=32)\n",
        "# we want to test whole data at once so create batch size = size of data set here 26\n",
        "test_data_loader = DataLoader(test_data,batch_size=26)"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNl6jLetI_j_"
      },
      "source": [
        "# Model Creation and Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMzo7CY8NsUD"
      },
      "source": [
        "# I have created linear model \n",
        "# That why i wont be using activation function \n",
        "# since we know that without activation function whole neural network is a linear model \n",
        "# y = w1x1 + w2x2 + ..... w7X7 "
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4PnbWjPvK1On",
        "outputId": "9e53870a-d632-49b6-8b9b-e13ebe698472"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "helPbca2IdZy"
      },
      "source": [
        "class Linear_NN(nn.Module):\n",
        "  def __init__(self,input_shape,output_shape):\n",
        "    super(Linear_NN,self).__init__()\n",
        "    self.Layer = nn.Linear(input_shape,output_shape)\n",
        "\n",
        "  def forward(self,input):\n",
        "    return self.Layer(input)"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJztMj_PJ9pX",
        "outputId": "36a9ace8-a23a-48d4-9d65-662a0141c44c"
      },
      "source": [
        "model = Linear_NN(X.shape[1],y.shape[1])\n",
        "model"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear_NN(\n",
              "  (Layer): Linear(in_features=7, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz5id3DMLh67"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZuVynq_KRRe",
        "outputId": "b8a73ff0-74f0-4bf7-b376-3dcb63df722d"
      },
      "source": [
        "# Lets Train Model  \n",
        "n_epoch = 1000\n",
        "loss_matrix =[]\n",
        "for epoch in range(n_epoch):\n",
        "  if epoch%100 ==0:\n",
        "    print(f'Epoch {epoch}/{n_epoch} ')\n",
        "\n",
        "  for batch , (input,output) in enumerate(train_data_loader):\n",
        "\n",
        "    input.device_ = device \n",
        "    output.device_ = device\n",
        "   \n",
        "    optimizer.zero_grad()            # Removing previously stored Gradient \n",
        "    y_pred = model.forward(input)    # Feed Forward Network \n",
        "    loss = criterion(output,y_pred)  # Loss Calculation \n",
        "    loss.backward()                  # d(loss)/dw \n",
        "    optimizer.step()                 # w = w - nd(loss)/dw\n",
        "    if epoch%100 == 0:\n",
        "     print(f'    Batch : {batch}  Loss : {loss.item()} ')\n",
        "\n",
        "  loss_matrix.append(loss.item())\n"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/1000 \n",
            "    Batch : 0  Loss : 42068.75390625 \n",
            "    Batch : 1  Loss : 39487.88671875 \n",
            "    Batch : 2  Loss : 38999.28125 \n",
            "Epoch 100/1000 \n",
            "    Batch : 0  Loss : 669.0714721679688 \n",
            "    Batch : 1  Loss : 839.951416015625 \n",
            "    Batch : 2  Loss : 785.2457275390625 \n",
            "Epoch 200/1000 \n",
            "    Batch : 0  Loss : 550.010009765625 \n",
            "    Batch : 1  Loss : 704.3904418945312 \n",
            "    Batch : 2  Loss : 640.0328979492188 \n",
            "Epoch 300/1000 \n",
            "    Batch : 0  Loss : 463.3839111328125 \n",
            "    Batch : 1  Loss : 576.6366577148438 \n",
            "    Batch : 2  Loss : 527.2811279296875 \n",
            "Epoch 400/1000 \n",
            "    Batch : 0  Loss : 385.7088317871094 \n",
            "    Batch : 1  Loss : 457.9784240722656 \n",
            "    Batch : 2  Loss : 429.4897766113281 \n",
            "Epoch 500/1000 \n",
            "    Batch : 0  Loss : 318.47747802734375 \n",
            "    Batch : 1  Loss : 356.9642028808594 \n",
            "    Batch : 2  Loss : 346.8855285644531 \n",
            "Epoch 600/1000 \n",
            "    Batch : 0  Loss : 263.0095520019531 \n",
            "    Batch : 1  Loss : 276.7575988769531 \n",
            "    Batch : 2  Loss : 279.89935302734375 \n",
            "Epoch 700/1000 \n",
            "    Batch : 0  Loss : 219.09727478027344 \n",
            "    Batch : 1  Loss : 216.4447479248047 \n",
            "    Batch : 2  Loss : 227.27047729492188 \n",
            "Epoch 800/1000 \n",
            "    Batch : 0  Loss : 185.42906188964844 \n",
            "    Batch : 1  Loss : 172.86865234375 \n",
            "    Batch : 2  Loss : 186.66319274902344 \n",
            "Epoch 900/1000 \n",
            "    Batch : 0  Loss : 160.16015625 \n",
            "    Batch : 1  Loss : 142.1487274169922 \n",
            "    Batch : 2  Loss : 155.46377563476562 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2AIx4BsNGQK",
        "outputId": "8f8fc36f-403c-443b-c630-d573128674d6"
      },
      "source": [
        "# Lets test Our model Now \n",
        "with torch.no_grad():\n",
        "  for batch , (input,output) in enumerate(test_data_loader):\n",
        "    input.device_ = device \n",
        "    output.device_ = device\n",
        "\n",
        "    y_pred = model.forward(input)\n",
        "    loss = criterion(output,y_pred)\n",
        "    \n",
        "    print(f'Loss : {loss.item()}')"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 117.94634246826172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-qVMG2eNQGt"
      },
      "source": [
        "# Test our model on Custom Data \n",
        "# since we have 7 Columns lets generate 7 random values \n",
        "data = torch.randint(10,50,(7,)).reshape(1,7)"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLnNxKrCPvUa",
        "outputId": "da15a116-adbf-4487-f305-776d57156180"
      },
      "source": [
        "# Getting 3 values at output \n",
        "# so our model is working fine \n",
        "model.forward(data.float())"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.2538, -1.5809,  9.9382]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBKyW01GQmPK"
      },
      "source": [
        "# Lets Implement Non Linear Model (Sequential Implementation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LsSwZO7QYbB"
      },
      "source": [
        "# Sequential implementation of seq model \n",
        "class Non_Linear_NN(nn.Module):\n",
        "  def __init__(self,input_shape,output_shape):\n",
        "    super(Non_Linear_NN,self).__init__()\n",
        "    self.Layers = nn.Sequential(\n",
        "        nn.Linear(input_shape,24),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(24,output_shape),\n",
        "    )\n",
        "  \n",
        "  def forward(self,input):\n",
        "    return self.Layers(input)"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jIHVhijSZ_M",
        "outputId": "2dd5afbc-ab83-4170-9639-3f258f4be92f"
      },
      "source": [
        "model = Non_Linear_NN(X.shape[1],y.shape[1])\n",
        "model"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Non_Linear_NN(\n",
              "  (Layers): Sequential(\n",
              "    (0): Linear(in_features=7, out_features=24, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=24, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhf7KBtIfzEU"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDL4-t1tScp9",
        "outputId": "89e50772-6ece-40ee-ef34-7b045b15a87b"
      },
      "source": [
        "# Lets Train Model  \n",
        "n_epoch = 200\n",
        "loss_matrix =[]\n",
        "for epoch in range(n_epoch):\n",
        "  if epoch%50 == 0:\n",
        "    print(f'Epoch {epoch}/{n_epoch} ')\n",
        "  \n",
        "  for batch , (input,output) in enumerate(train_data_loader):\n",
        "    input.device_ = device \n",
        "    output.device_ = device\n",
        "\n",
        "    optimizer.zero_grad()            # Removing previously stored Gradient \n",
        "    y_pred = model.forward(input)    # Feed Forward Network \n",
        "    loss = criterion(output,y_pred)  # Loss Calculation \n",
        "    loss.backward()                  # d(loss)/dw \n",
        "    optimizer.step()                 # w = w - nd(loss)/dw\n",
        "\n",
        "    if epoch%50==0:\n",
        "      print(f'    Batch : {batch}  Loss : {loss.item()} ')\n",
        "\n",
        "  loss_matrix.append(loss.item())\n"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200 \n",
            "    Batch : 0  Loss : 12037.0888671875 \n",
            "    Batch : 1  Loss : 10193.9482421875 \n",
            "    Batch : 2  Loss : 9672.953125 \n",
            "Epoch 50/200 \n",
            "    Batch : 0  Loss : 223.0378875732422 \n",
            "    Batch : 1  Loss : 180.7134246826172 \n",
            "    Batch : 2  Loss : 200.82286071777344 \n",
            "Epoch 100/200 \n",
            "    Batch : 0  Loss : 155.7143096923828 \n",
            "    Batch : 1  Loss : 126.11968231201172 \n",
            "    Batch : 2  Loss : 136.8185272216797 \n",
            "Epoch 150/200 \n",
            "    Batch : 0  Loss : 124.65538787841797 \n",
            "    Batch : 1  Loss : 103.64739990234375 \n",
            "    Batch : 2  Loss : 103.22954559326172 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cATTg3glSp1-",
        "outputId": "77b7f8fe-9805-4750-f53e-8951fa3a4644"
      },
      "source": [
        "# Lets test Our model Now \n",
        "with torch.no_grad():\n",
        "  for batch , (input,output) in enumerate(test_data_loader):\n",
        "    input.device_ = device \n",
        "    output.device_ = device\n",
        "\n",
        "    y_pred = model.forward(input)\n",
        "    loss = criterion(output,y_pred)\n",
        "    \n",
        "    print(f'Loss : {loss.item()}')"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 97.08958435058594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dil_U2sKgDW0"
      },
      "source": [
        "# Test our model on Custom Data \n",
        "# since we have 7 Columns lets generate 7 random values \n",
        "data = torch.randint(10,50,(7,)).reshape(1,7)"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inPJdbhdgIO_",
        "outputId": "ef864551-aad4-46a8-bb05-321ed425bf71"
      },
      "source": [
        "model.forward(data.float())"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.3335, -4.9292,  3.8402]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMTe5vQsgmmJ"
      },
      "source": [
        "# Lets Implement Non Linear Model (Functional Implementation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLtGwdSggacN"
      },
      "source": [
        "# Functional Implementation \n",
        "class Non_Linear_NN(nn.Module):\n",
        "  def __init__(self,input_shape,output_shape):\n",
        "    super(Non_Linear_NN,self).__init__()\n",
        "    self.Layer1 = nn.Linear(input_shape,14)\n",
        "    self.activation = nn.ReLU()\n",
        "    self.Layer2 = nn.Linear(14,output_shape)\n",
        "  \n",
        "  def forward(self,input):\n",
        "    x = self.Layer1(input)\n",
        "    x = self.activation(x)\n",
        "    x = self.Layer2(x)\n",
        "    return x"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4uCYAdbhLHb",
        "outputId": "aff4dd67-0ad5-4aed-e67a-744cea32139e"
      },
      "source": [
        "model = Non_Linear_NN(X.shape[1],y.shape[1])\n",
        "model"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Non_Linear_NN(\n",
              "  (Layer1): Linear(in_features=7, out_features=14, bias=True)\n",
              "  (activation): ReLU()\n",
              "  (Layer2): Linear(in_features=14, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj7weJjXhOBz"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cubb_QXqhUsX",
        "outputId": "cd04bc99-a43b-4dc4-be7a-3e2df830a3ae"
      },
      "source": [
        "# Lets Train Model  \n",
        "n_epoch = 200\n",
        "loss_matrix =[]\n",
        "for epoch in range(n_epoch):\n",
        "  if epoch%50 == 0:\n",
        "    print(f'Epoch {epoch}/{n_epoch} ')\n",
        "  \n",
        "  for batch , (input,output) in enumerate(train_data_loader):\n",
        "    input.device_ = device \n",
        "    output.device_ = device\n",
        "\n",
        "    optimizer.zero_grad()            # Removing previously stored Gradient \n",
        "    y_pred = model.forward(input)    # Feed Forward Network \n",
        "    loss = criterion(output,y_pred)  # Loss Calculation \n",
        "    loss.backward()                  # d(loss)/dw \n",
        "    optimizer.step()                 # w = w - nd(loss)/dw\n",
        "\n",
        "    if epoch%50==0:\n",
        "      print(f'    Batch : {batch}  Loss : {loss.item()} ')\n",
        "\n",
        "  loss_matrix.append(loss.item())"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200 \n",
            "    Batch : 0  Loss : 146.9462127685547 \n",
            "    Batch : 1  Loss : 102.46778106689453 \n",
            "    Batch : 2  Loss : 198.8376922607422 \n",
            "Epoch 50/200 \n",
            "    Batch : 0  Loss : 131.5950927734375 \n",
            "    Batch : 1  Loss : 97.1766357421875 \n",
            "    Batch : 2  Loss : 167.99667358398438 \n",
            "Epoch 100/200 \n",
            "    Batch : 0  Loss : 119.29925537109375 \n",
            "    Batch : 1  Loss : 92.20316314697266 \n",
            "    Batch : 2  Loss : 144.0394744873047 \n",
            "Epoch 150/200 \n",
            "    Batch : 0  Loss : 108.0706558227539 \n",
            "    Batch : 1  Loss : 87.41178131103516 \n",
            "    Batch : 2  Loss : 125.18489837646484 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_BNEMbUhVRn",
        "outputId": "7dc6bed7-39d7-4746-97e4-47fc287e1791"
      },
      "source": [
        "# Lets test Our model Now \n",
        "with torch.no_grad():\n",
        "  for batch , (input,output) in enumerate(test_data_loader):\n",
        "    input.device_ = device \n",
        "    output.device_ = device\n",
        "\n",
        "    y_pred = model.forward(input)\n",
        "    loss = criterion(output,y_pred)\n",
        "    \n",
        "    print(f'Loss : {loss.item()}')"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 125.61939239501953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0U8d-U_hdOG",
        "outputId": "4a52d122-20de-47e8-ae5e-8c38bf8bb32f"
      },
      "source": [
        "# Test our model on Custom Data \n",
        "# since we have 7 Columns lets generate 7 random values \n",
        "data = torch.randint(10,50,(7,)).reshape(1,7)\n",
        "model.forward(data.float())"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3259, 2.3484, 4.8835]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EVa7oEHhtPI"
      },
      "source": [
        "# Conclusion \n",
        "\n",
        "1. When i trained linear model it took 1000 epoch to get a good accuracy.\n",
        "2. But when i introduced non Linearity it got good accuracy in just 400 epochs.\n"
      ]
    }
  ]
}